# Ubuntu 22.04
=> Tạo User mới:
# Tạo group: 
sudo groupadd ZeroX
# Add user: 
sudo useradd -md /home/ZeroX -s /bin/bash -g ZeroX ZeroX
# Cập nhật password: 
sudo su - 
sudo paswd ZeroX
# Cập nhật quyền usermod:
sudo usermod -aG sudo ZeroX
# Truy câp vào User: 
sudo su - ZeroX

=> Cài đặt Hadoop: 
# Môi trường java: 
sudo apt install openjdk-8-jdk
java -version
# Cài đặt Remote ssh: 
sudo apt install openssh-server openssh-client -y
ssh-keygen -t rsa
<Lưu ý: Nếu có bug thì sudo chmod 755 <Folder>> 
# Tải File cài đặt Hadoop: 
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
# Giải nén: 
tar -xvzf hadoop-3.3.4.tar.gz
# Di chuyển tới /usr/local/hadoop
sudo mv hadoop-3.3.4 /usr/local/hadoop
# Tạo file logs
sudo mkdir /usr/local/hadoop/logs
sudo chown -R ZeroX:ZeroX /usr/local/hadoop
# Tiến hành lưu thêm 1 số thông tin 
## sudo nano ~/.bashrc
export HADOOP_HOME=/usr/local/hadoop

export HADOOP_INSTALL=$HADOOP_HOME

export HADOOP_MAPRED_HOME=$HADOOP_HOME

export HADOOP_COMMON_HOME=$HADOOP_HOME

export HADOOP_HDFS_HOME=$HADOOP_HOME

export YARN_HOME=$HADOOP_HOME

export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native

export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
## source ~/.bashrc
which javac: Tìm Java path
readlink -f /usr/bin/javac: Tìm OpenJDK directory
# Edit hadoop-env.sh: 
## sudo nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

export HADOOP_CLASSPATH+=" $HADOOP_HOME/lib/*.jar"
# Browse to the hadoop lib directory
cd /usr/local/hadoop/lib
# Download the Javax activation file
sudo wget https://jcenter.bintray.com/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar
# Verify the Hadoop version
## sudo nano $HADOOP_HOME/etc/hadoop/core-site.xml
<configuration>

   <property>

      <name>fs.default.name</name>

      <value>hdfs://0.0.0.0:9000</value>

      <description>The default file system URI</description>

   </property>

</configuration>

# Create a directory for storing node metadata and change the ownership to ZeroX.
sudo mkdir -p /home/ZeroX/hdfs/{namenode,datanode}
sudo chown -R ZeroX:ZeroX /home/ZeroX/hdfs
# Edit mapred-site.xml configuration file to define MapReduce values.
## sudo nano $HADOOP_HOME/etc/hadoop/mapred-site.xml
<configuration>

   <property>

      <name>dfs.replication</name>

      <value>1</value>

   </property>



   <property>

      <name>dfs.name.dir</name>

      <value>file:///home/ZeroX/hdfs/namenode</value>

   </property>



   <property>

      <name>dfs.data.dir</name>

      <value>file:///home/ZeroX/hdfs/datanode</value>

   </property>

</configuration>

# Edit the yarn-site.xml configuration file and define YARN-related settings.
## sudo nano $HADOOP_HOME/etc/hadoop/yarn-site.xml
<configuration>

   <property>

      <name>yarn.nodemanager.aux-services</name>

      <value>mapreduce_shuffle</value>

   </property>

</configuration>

# Validate the Hadoop configuration and format the HDFS NameNode.
hdfs namenode -format
# Start the Apache Hadoop Cluster
start-all.sh
jps
# Access Web
http://localhost:9870/dfshealth.html#tab-overview